{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Google BigQuery Social Listening Data Export\n\nThis notebook connects to BigQuery using Google Cloud CLI authentication and exports social media listening data to CSV.\n\n## Prerequisites Setup Guide\n\n### 1. Install Required Tools\n\nBefore using this notebook, you need to install:\n\n1. **uv** (Python package manager):\n   ```bash\n   # On macOS/Linux\n   curl -LsSf https://astral.sh/uv/install.sh | sh\n   \n   # On Windows\n   powershell -c \"irm https://astral.sh/uv/install.ps1 | iex\"\n   ```\n\n2. **Google Cloud CLI**:\n   - Download from: https://cloud.google.com/sdk/docs/install\n   - Follow the installation instructions for your operating system\n\n### 2. Set Up Project Environment\n\nIn your terminal (not in this notebook):\n\n```bash\n# Navigate to project directory\ncd /path/to/google-cloud-proj\n\n# Install Python dependencies\nuv sync\n\n# Start Jupyter Notebook with the correct environment\nuv run jupyter notebook\n```\n\n### 3. Authenticate with Google Cloud\n\nRun this command in your terminal (only needed once per machine):\n\n```bash\n# Authenticate with Google Cloud\ngcloud auth application-default login\n\n# Set your default project\ngcloud config set project sinnia-gnp  # Replace with your project ID\n```\n\n### 4. Common Issues and Solutions\n\n- **Import errors**: Make sure you started Jupyter with `uv run jupyter notebook`\n- **Authentication errors**: Run `gcloud auth application-default login` in your terminal\n- **Permission errors**: Ensure your Google account has BigQuery access for the project",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 0. Virtual Environment Setup\n\n**IMPORTANT**: This notebook requires the proper Python environment with all dependencies installed.\n\nIf you're seeing import errors, you need to:\n1. Install dependencies using `uv sync` in the terminal\n2. Start Jupyter with `uv run jupyter notebook` or `uv run jupyter lab`\n\nThe cell below will check if the environment is set up correctly.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Check if running in the correct environment\nimport sys\nimport os\n\nprint(\"Python executable:\", sys.executable)\nprint(\"Python version:\", sys.version)\n\n# Try to import required packages\ntry:\n    import google.cloud.bigquery\n    print(\"✓ google-cloud-bigquery is installed\")\nexcept ImportError:\n    print(\"❌ google-cloud-bigquery is NOT installed\")\n    print(\"\\nTo fix this:\")\n    print(\"1. Close this notebook\")\n    print(\"2. In your terminal, run: uv sync\")\n    print(\"3. Start Jupyter with: uv run jupyter notebook\")\n    print(\"\\nIf you're already running with uv run, try restarting the kernel.\")\n\ntry:\n    import pandas\n    print(\"✓ pandas is installed\")\nexcept ImportError:\n    print(\"❌ pandas is NOT installed\")\n\n# Check if we're in a virtual environment\nif hasattr(sys, 'real_prefix') or (hasattr(sys, 'base_prefix') and sys.base_prefix != sys.prefix):\n    print(\"\\n✓ Running in a virtual environment\")\nelse:\n    print(\"\\n⚠️  Not running in a virtual environment - packages may not be available\")",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# Import helper functions from main.py\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.path.abspath('')))\n",
    "from main import get_bigquery_client, query_to_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Application Default Credentials not found\n",
      "   Please run: gcloud auth application-default login\n",
      "   Or install gcloud CLI from: https://cloud.google.com/sdk/docs/install\n"
     ]
    }
   ],
   "source": [
    "# Using Google Cloud CLI authentication (Application Default Credentials)\n",
    "# Make sure you've run: gcloud auth application-default login\n",
    "\n",
    "project_id = os.getenv('GOOGLE_CLOUD_PROJECT', 'sinnia-gnp')  # Default to sinnia-gnp if not set\n",
    "\n",
    "# Check if Application Default Credentials are available\n",
    "try:\n",
    "    from google.auth import default\n",
    "    credentials, project = default()\n",
    "    print(\"✓ Using Application Default Credentials\")\n",
    "    if project:\n",
    "        print(f\"✓ Default project from gcloud: {project}\")\n",
    "        if not project_id:\n",
    "            project_id = project\n",
    "except Exception as e:\n",
    "    print(\"❌ Application Default Credentials not found\")\n",
    "    print(\"   Please run: gcloud auth application-default login\")\n",
    "    print(\"   Or install gcloud CLI from: https://cloud.google.com/sdk/docs/install\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## 2. Authentication Setup\n\nRun the cell below to set up Google Cloud authentication. This only needs to be done once per machine.\n\n**Note:** This will open a browser window where you'll need to log in with your Google account that has access to the BigQuery project.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# If Application Default Credentials are not set up, run this cell to authenticate\n# This will open a browser window for authentication\nimport subprocess\nimport sys\n\ntry:\n    # Check if ADC exists\n    from google.auth import default\n    credentials, project = default()\n    print(\"✓ Application Default Credentials already configured\")\nexcept:\n    print(\"Setting up Application Default Credentials...\")\n    print(\"A browser window will open for authentication.\")\n    print(\"Please log in with your Google account that has access to the BigQuery project.\\n\")\n    \n    try:\n        # Run gcloud auth command\n        result = subprocess.run(\n            [\"gcloud\", \"auth\", \"application-default\", \"login\"],\n            capture_output=True,\n            text=True\n        )\n        \n        if result.returncode == 0:\n            print(\"\\n✓ Authentication successful!\")\n            print(\"Application Default Credentials have been saved.\")\n        else:\n            print(f\"\\n❌ Authentication failed: {result.stderr}\")\n            print(\"\\nPlease run this command manually in your terminal:\")\n            print(\"gcloud auth application-default login\")\n    except FileNotFoundError:\n        print(\"❌ gcloud CLI not found. Please install it first:\")\n        print(\"https://cloud.google.com/sdk/docs/install\")\n        print(\"\\nOr run this command in your terminal after installing:\")\n        print(\"gcloud auth application-default login\")",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Initialize BigQuery client with Application Default Credentials\ntry:\n    # No need to pass credentials when using ADC\n    client = bigquery.Client(project=project_id)\n    print(f\"✓ Connected to BigQuery project: {client.project}\")\nexcept Exception as e:\n    print(f\"❌ Error connecting to BigQuery: {e}\")\n    print(\"   Please ensure you have run: gcloud auth application-default login\")\n    print(\"   And that you have access to the project\")",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Check for credentials configuration\n# Option 1: Service account file (if you have one)\ncredentials_path = os.getenv('GOOGLE_APPLICATION_CREDENTIALS')\n\n# Option 2: Use Application Default Credentials (recommended)\n# No credentials_path needed - just ensure you've run:\n# gcloud auth application-default login\n\nif credentials_path and credentials_path.strip() and os.path.exists(credentials_path):\n    print(f\"✓ Service account credentials file found: {credentials_path}\")\nelse:\n    print(\"ℹ️ No service account file configured.\")\n    print(\"   Using Application Default Credentials instead.\")\n    print(\"   Make sure you've run: gcloud auth application-default login\")\n    credentials_path = None  # Explicitly set to None to use ADC"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Initialize BigQuery client\ntry:\n    # Use Application Default Credentials by not passing credentials_path\n    client = get_bigquery_client(project_id=project_id)\n    print(f\"✓ Connected to BigQuery project: {client.project}\")\nexcept Exception as e:\n    print(f\"❌ Error connecting to BigQuery: {e}\")\n    print(\"   Please check your credentials and project ID\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define and Run Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the query\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    platform, \n",
    "    CAST(created_at AS STRING FORMAT 'YYYY-MM-DD HH24:MI') AS creado, \n",
    "    user_id, \n",
    "    user, \n",
    "    CAST(followers AS STRING) AS seguidores,\n",
    "    text, \n",
    "    CAST(likes_reactions AS STRING) AS likes, \n",
    "    CAST(comments AS STRING) AS comentarios, \n",
    "    CAST(shares_retweets AS STRING) AS compartidos,\n",
    "    CAST(engagements AS STRING) AS enganches,\n",
    "    CAST(views AS STRING) AS vistas\n",
    "FROM `sinnia-gnp.social_dashboard_table.listening_table_prd` \n",
    "WHERE created_at >= '2025-05-12' \n",
    "    AND created_at < '2025-05-14'\n",
    "    AND topic_id = 238\n",
    "    AND NOT (\n",
    "        CONTAINS_SUBSTR(text, \"Estadio GNP\") \n",
    "        OR CONTAINS_SUBSTR(text, \"Auditorio GNP\") \n",
    "        OR CONTAINS_SUBSTR(text, \"el GNP\") \n",
    "        OR CONTAINS_SUBSTR(text, \"Foro GNP\")\n",
    "    )\n",
    "\"\"\"\n",
    "\n",
    "print(\"Query defined successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run query and get results as DataFrame\n",
    "print(\"Running query...\")\n",
    "try:\n",
    "    df = client.query(query).to_dataframe()\n",
    "    print(f\"✓ Query completed successfully\")\n",
    "    print(f\"✓ Retrieved {len(df):,} rows\")\n",
    "    print(f\"\\nColumns: {', '.join(df.columns)}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error running query: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preview Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "print(\"\\nFirst 5 rows of data:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(f\"Total rows: {len(df):,}\")\n",
    "print(f\"\\nPlatform distribution:\")\n",
    "print(df['platform'].value_counts())\n",
    "print(f\"\\nDate range: {df['creado'].min()} to {df['creado'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Export to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data directory if it doesn't exist\n",
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "# Generate filename with timestamp\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "filename = f'social_listening_topic238_{timestamp}.csv'\n",
    "filepath = os.path.join('data', filename)\n",
    "\n",
    "# Export to CSV\n",
    "df.to_csv(filepath, index=False, encoding='utf-8')\n",
    "print(f\"✓ Data exported to: {filepath}\")\n",
    "print(f\"✓ File size: {os.path.getsize(filepath) / 1024 / 1024:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Alternative: Direct Query to CSV (for large datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this method for very large datasets to avoid memory issues\n",
    "# Uncomment to use:\n",
    "\n",
    "# large_filename = f'social_listening_topic238_large_{timestamp}.csv'\n",
    "# large_filepath = os.path.join('data', large_filename)\n",
    "\n",
    "# # Export in chunks of 10,000 rows\n",
    "# query_to_csv(client, query, large_filepath, chunk_size=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The social listening data has been successfully exported. You can find your CSV file in the `data/` directory.\n",
    "\n",
    "### Next Steps:\n",
    "1. Check the exported CSV file in the `data/` folder\n",
    "2. Modify the date range in the query to export different time periods\n",
    "3. Adjust the topic_id to query different topics\n",
    "4. Add additional filters or columns as needed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}