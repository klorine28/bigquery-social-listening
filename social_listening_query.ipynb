{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Social Listening Data Export\n",
    "\n",
    "This notebook connects to BigQuery and exports social media listening data to CSV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# Import helper functions from main.py\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.path.abspath('')))\n",
    "from main import get_bigquery_client, query_to_csv"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Using Google Cloud CLI authentication (Application Default Credentials)\n# Make sure you've run: gcloud auth application-default login\n\nproject_id = os.getenv('GOOGLE_CLOUD_PROJECT', 'sinnia-gnp')  # Default to sinnia-gnp if not set\n\n# Check if Application Default Credentials are available\ntry:\n    from google.auth import default\n    credentials, project = default()\n    print(\"✓ Using Application Default Credentials\")\n    if project:\n        print(f\"✓ Default project from gcloud: {project}\")\n        if not project_id:\n            project_id = project\nexcept Exception as e:\n    print(\"❌ Application Default Credentials not found\")\n    print(\"   Please run: gcloud auth application-default login\")\n    print(\"   Or install gcloud CLI from: https://cloud.google.com/sdk/docs/install\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Initialize BigQuery client with Application Default Credentials\ntry:\n    # No need to pass credentials when using ADC\n    client = bigquery.Client(project=project_id)\n    print(f\"✓ Connected to BigQuery project: {client.project}\")\nexcept Exception as e:\n    print(f\"❌ Error connecting to BigQuery: {e}\")\n    print(\"   Please ensure you have run: gcloud auth application-default login\")\n    print(\"   And that you have access to the project\")",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Use environment variables\n",
    "credentials_path = os.getenv('GOOGLE_APPLICATION_CREDENTIALS')\n",
    "project_id = os.getenv('GOOGLE_CLOUD_PROJECT', 'sinnia-gnp')  # Default to sinnia-gnp if not set\n",
    "\n",
    "# Option 2: Set paths directly (uncomment and update if not using .env)\n",
    "# credentials_path = 'path/to/your/service-account-key.json'\n",
    "# project_id = 'sinnia-gnp'\n",
    "\n",
    "# Verify credentials path exists\n",
    "if credentials_path and os.path.exists(credentials_path):\n",
    "    print(f\"✓ Credentials file found: {credentials_path}\")\n",
    "else:\n",
    "    print(\"❌ Credentials file not found. Please update the path.\")\n",
    "    print(\"   Set GOOGLE_APPLICATION_CREDENTIALS in .env or update credentials_path above\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize BigQuery client\n",
    "try:\n",
    "    client = get_bigquery_client(credentials_path=credentials_path, project_id=project_id)\n",
    "    print(f\"✓ Connected to BigQuery project: {client.project}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error connecting to BigQuery: {e}\")\n",
    "    print(\"   Please check your credentials and project ID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define and Run Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the query\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    platform, \n",
    "    CAST(created_at AS STRING FORMAT 'YYYY-MM-DD HH24:MI') AS creado, \n",
    "    user_id, \n",
    "    user, \n",
    "    CAST(followers AS STRING) AS seguidores,\n",
    "    text, \n",
    "    CAST(likes_reactions AS STRING) AS likes, \n",
    "    CAST(comments AS STRING) AS comentarios, \n",
    "    CAST(shares_retweets AS STRING) AS compartidos,\n",
    "    CAST(engagements AS STRING) AS enganches,\n",
    "    CAST(views AS STRING) AS vistas\n",
    "FROM `sinnia-gnp.social_dashboard_table.listening_table_prd` \n",
    "WHERE created_at >= '2025-05-12' \n",
    "    AND created_at < '2025-05-14'\n",
    "    AND topic_id = 238\n",
    "    AND NOT (\n",
    "        CONTAINS_SUBSTR(text, \"Estadio GNP\") \n",
    "        OR CONTAINS_SUBSTR(text, \"Auditorio GNP\") \n",
    "        OR CONTAINS_SUBSTR(text, \"el GNP\") \n",
    "        OR CONTAINS_SUBSTR(text, \"Foro GNP\")\n",
    "    )\n",
    "\"\"\"\n",
    "\n",
    "print(\"Query defined successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run query and get results as DataFrame\n",
    "print(\"Running query...\")\n",
    "try:\n",
    "    df = client.query(query).to_dataframe()\n",
    "    print(f\"✓ Query completed successfully\")\n",
    "    print(f\"✓ Retrieved {len(df):,} rows\")\n",
    "    print(f\"\\nColumns: {', '.join(df.columns)}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error running query: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preview Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "print(\"\\nFirst 5 rows of data:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(f\"Total rows: {len(df):,}\")\n",
    "print(f\"\\nPlatform distribution:\")\n",
    "print(df['platform'].value_counts())\n",
    "print(f\"\\nDate range: {df['creado'].min()} to {df['creado'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Export to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data directory if it doesn't exist\n",
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "# Generate filename with timestamp\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "filename = f'social_listening_topic238_{timestamp}.csv'\n",
    "filepath = os.path.join('data', filename)\n",
    "\n",
    "# Export to CSV\n",
    "df.to_csv(filepath, index=False, encoding='utf-8')\n",
    "print(f\"✓ Data exported to: {filepath}\")\n",
    "print(f\"✓ File size: {os.path.getsize(filepath) / 1024 / 1024:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Alternative: Direct Query to CSV (for large datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this method for very large datasets to avoid memory issues\n",
    "# Uncomment to use:\n",
    "\n",
    "# large_filename = f'social_listening_topic238_large_{timestamp}.csv'\n",
    "# large_filepath = os.path.join('data', large_filename)\n",
    "\n",
    "# # Export in chunks of 10,000 rows\n",
    "# query_to_csv(client, query, large_filepath, chunk_size=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The social listening data has been successfully exported. You can find your CSV file in the `data/` directory.\n",
    "\n",
    "### Next Steps:\n",
    "1. Check the exported CSV file in the `data/` folder\n",
    "2. Modify the date range in the query to export different time periods\n",
    "3. Adjust the topic_id to query different topics\n",
    "4. Add additional filters or columns as needed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}