{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google BigQuery Social Listening Data Export\n",
    "\n",
    "This notebook connects to BigQuery using Google Cloud CLI authentication and exports social media listening data to CSV.\n",
    "\n",
    "## Prerequisites Setup Guide\n",
    "\n",
    "### 1. Install Required Tools\n",
    "\n",
    "Before using this notebook, you need to install:\n",
    "\n",
    "1. **uv** (Python package manager):\n",
    "   ```bash\n",
    "   # On macOS/Linux\n",
    "   curl -LsSf https://astral.sh/uv/install.sh | sh\n",
    "   \n",
    "   # On Windows\n",
    "   powershell -c \"irm https://astral.sh/uv/install.ps1 | iex\"\n",
    "   ```\n",
    "\n",
    "2. **Google Cloud CLI**:\n",
    "   - Download from: https://cloud.google.com/sdk/docs/install\n",
    "   - Follow the installation instructions for your operating system\n",
    "\n",
    "### 2. Set Up Project Environment\n",
    "\n",
    "In your terminal (not in this notebook):\n",
    "\n",
    "```bash\n",
    "# Navigate to project directory\n",
    "cd /path/to/google-cloud-proj\n",
    "\n",
    "# Install Python dependencies\n",
    "uv sync\n",
    "\n",
    "# Start Jupyter Notebook with the correct environment\n",
    "uv run jupyter notebook\n",
    "```\n",
    "\n",
    "### 3. Authenticate with Google Cloud\n",
    "\n",
    "Run this command in your terminal (only needed once per machine):\n",
    "\n",
    "```bash\n",
    "# Authenticate with Google Cloud\n",
    "gcloud auth application-default login\n",
    "\n",
    "# Set your default project\n",
    "gcloud config set project sinnia-gnp  # Replace with your project ID\n",
    "```\n",
    "\n",
    "### 4. Common Issues and Solutions\n",
    "\n",
    "- **Import errors**: Make sure you started Jupyter with `uv run jupyter notebook`\n",
    "- **Authentication errors**: Run `gcloud auth application-default login` in your terminal\n",
    "- **Permission errors**: Ensure your Google account has BigQuery access for the project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Virtual Environment Setup\n",
    "\n",
    "**IMPORTANT**: This notebook requires the proper Python environment with all dependencies installed.\n",
    "\n",
    "If you're seeing import errors, you need to:\n",
    "1. Install dependencies using `uv sync` in the terminal\n",
    "2. Start Jupyter with `uv run jupyter notebook` or `uv run jupyter lab`\n",
    "\n",
    "The cell below will check if the environment is set up correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python executable: /mnt/d/google_cloud_proj/.venv/bin/python3\n",
      "Python version: 3.12.3 (main, Feb  4 2025, 14:48:35) [GCC 13.3.0]\n",
      "✓ google-cloud-bigquery is installed\n",
      "✓ pandas is installed\n",
      "\n",
      "✓ Running in a virtual environment\n"
     ]
    }
   ],
   "source": [
    "# Check if running in the correct environment\n",
    "import sys\n",
    "import os\n",
    "\n",
    "print(\"Python executable:\", sys.executable)\n",
    "print(\"Python version:\", sys.version)\n",
    "\n",
    "# Try to import required packages\n",
    "try:\n",
    "    import google.cloud.bigquery\n",
    "    print(\"✓ google-cloud-bigquery is installed\")\n",
    "except ImportError:\n",
    "    print(\"❌ google-cloud-bigquery is NOT installed\")\n",
    "    print(\"\\nTo fix this:\")\n",
    "    print(\"1. Close this notebook\")\n",
    "    print(\"2. In your terminal, run: uv sync\")\n",
    "    print(\"3. Start Jupyter with: uv run jupyter notebook\")\n",
    "    print(\"\\nIf you're already running with uv run, try restarting the kernel.\")\n",
    "\n",
    "try:\n",
    "    import pandas\n",
    "    print(\"✓ pandas is installed\")\n",
    "except ImportError:\n",
    "    print(\"❌ pandas is NOT installed\")\n",
    "\n",
    "# Check if we're in a virtual environment\n",
    "if hasattr(sys, 'real_prefix') or (hasattr(sys, 'base_prefix') and sys.base_prefix != sys.prefix):\n",
    "    print(\"\\n✓ Running in a virtual environment\")\n",
    "else:\n",
    "    print(\"\\n⚠️  Not running in a virtual environment - packages may not be available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# Import helper functions from main.py\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.path.abspath('')))\n",
    "from main import get_bigquery_client, query_to_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/google_cloud_proj/.venv/lib/python3.12/site-packages/google/auth/_default.py:76: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. See the following page for troubleshooting: https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds. \n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Using Application Default Credentials\n",
      "✓ Default project from gcloud: sinnia-gnp\n"
     ]
    }
   ],
   "source": [
    "# Using Google Cloud CLI authentication (Application Default Credentials)\n",
    "# Make sure you've run: gcloud auth application-default login\n",
    "\n",
    "project_id = os.getenv('GOOGLE_CLOUD_PROJECT', 'sinnia-gnp')  # Default to sinnia-gnp if not set\n",
    "\n",
    "# Check if Application Default Credentials are available\n",
    "try:\n",
    "    from google.auth import default\n",
    "    credentials, project = default()\n",
    "    print(\"✓ Using Application Default Credentials\")\n",
    "    if project:\n",
    "        print(f\"✓ Default project from gcloud: {project}\")\n",
    "        if not project_id:\n",
    "            project_id = project\n",
    "except Exception as e:\n",
    "    print(\"❌ Application Default Credentials not found\")\n",
    "    print(\"   Please run: gcloud auth application-default login\")\n",
    "    print(\"   Or install gcloud CLI from: https://cloud.google.com/sdk/docs/install\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Authentication Setup\n",
    "\n",
    "Run the cell below to set up Google Cloud authentication. This only needs to be done once per machine.\n",
    "\n",
    "**Note:** This will open a browser window where you'll need to log in with your Google account that has access to the BigQuery project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/google_cloud_proj/.venv/lib/python3.12/site-packages/google/auth/_default.py:76: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. See the following page for troubleshooting: https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds. \n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Application Default Credentials already configured\n"
     ]
    }
   ],
   "source": [
    "# If Application Default Credentials are not set up, run this cell to authenticate\n",
    "# This will open a browser window for authentication\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "try:\n",
    "    # Check if ADC exists\n",
    "    from google.auth import default\n",
    "    credentials, project = default()\n",
    "    print(\"✓ Application Default Credentials already configured\")\n",
    "except:\n",
    "    print(\"Setting up Application Default Credentials...\")\n",
    "    print(\"A browser window will open for authentication.\")\n",
    "    print(\"Please log in with your Google account that has access to the BigQuery project.\\n\")\n",
    "    \n",
    "    try:\n",
    "        # Run gcloud auth command\n",
    "        result = subprocess.run(\n",
    "            [\"gcloud\", \"auth\", \"application-default\", \"login\"],\n",
    "            capture_output=True,\n",
    "            text=True\n",
    "        )\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            print(\"\\n✓ Authentication successful!\")\n",
    "            print(\"Application Default Credentials have been saved.\")\n",
    "        else:\n",
    "            print(f\"\\n❌ Authentication failed: {result.stderr}\")\n",
    "            print(\"\\nPlease run this command manually in your terminal:\")\n",
    "            print(\"gcloud auth application-default login\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"❌ gcloud CLI not found. Please install it first:\")\n",
    "        print(\"https://cloud.google.com/sdk/docs/install\")\n",
    "        print(\"\\nOr run this command in your terminal after installing:\")\n",
    "        print(\"gcloud auth application-default login\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/google_cloud_proj/.venv/lib/python3.12/site-packages/google/auth/_default.py:76: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. See the following page for troubleshooting: https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds. \n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Connected to BigQuery project: sinnia-gnp\n"
     ]
    }
   ],
   "source": [
    "# Initialize BigQuery client with Application Default Credentials\n",
    "try:\n",
    "    # No need to pass credentials when using ADC\n",
    "    client = bigquery.Client(project=project_id)\n",
    "    print(f\"✓ Connected to BigQuery project: {client.project}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error connecting to BigQuery: {e}\")\n",
    "    print(\"   Please ensure you have run: gcloud auth application-default login\")\n",
    "    print(\"   And that you have access to the project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ℹ️ No service account file configured.\n",
      "   Using Application Default Credentials instead.\n",
      "   Make sure you've run: gcloud auth application-default login\n"
     ]
    }
   ],
   "source": [
    "# Check for credentials configuration\n",
    "# Option 1: Service account file (if you have one)\n",
    "credentials_path = os.getenv('GOOGLE_APPLICATION_CREDENTIALS')\n",
    "\n",
    "# Option 2: Use Application Default Credentials (recommended)\n",
    "# No credentials_path needed - just ensure you've run:\n",
    "# gcloud auth application-default login\n",
    "\n",
    "if credentials_path and credentials_path.strip() and os.path.exists(credentials_path):\n",
    "    print(f\"✓ Service account credentials file found: {credentials_path}\")\n",
    "else:\n",
    "    print(\"ℹ️ No service account file configured.\")\n",
    "    print(\"   Using Application Default Credentials instead.\")\n",
    "    print(\"   Make sure you've run: gcloud auth application-default login\")\n",
    "    credentials_path = None  # Explicitly set to None to use ADC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/google_cloud_proj/.venv/lib/python3.12/site-packages/google/auth/_default.py:76: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. See the following page for troubleshooting: https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds. \n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n",
      "/mnt/d/google_cloud_proj/.venv/lib/python3.12/site-packages/google/auth/_default.py:76: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. See the following page for troubleshooting: https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds. \n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Application Default Credentials for project: sinnia-gnp\n",
      "✓ Connected to BigQuery project: sinnia-gnp\n"
     ]
    }
   ],
   "source": [
    "# Initialize BigQuery client\n",
    "try:\n",
    "    # Use Application Default Credentials by not passing credentials_path\n",
    "    client = get_bigquery_client(project_id=project_id)\n",
    "    print(f\"✓ Connected to BigQuery project: {client.project}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error connecting to BigQuery: {e}\")\n",
    "    print(\"   Please check your credentials and project ID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define and Run Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query defined successfully\n"
     ]
    }
   ],
   "source": [
    "# Define the query\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    platform, \n",
    "    CAST(created_at AS STRING FORMAT 'YYYY-MM-DD HH24:MI') AS creado, \n",
    "    user_id, \n",
    "    user, \n",
    "    CAST(followers AS STRING) AS seguidores,\n",
    "    text, \n",
    "    CAST(likes_reactions AS STRING) AS likes, \n",
    "    CAST(comments AS STRING) AS comentarios, \n",
    "    CAST(shares_retweets AS STRING) AS compartidos,\n",
    "    CAST(engagements AS STRING) AS enganches,\n",
    "    CAST(views AS STRING) AS vistas\n",
    "FROM `sinnia-gnp.social_dashboard_table.listening_table_prd` \n",
    "WHERE created_at >= '2025-05-12' \n",
    "    AND created_at < '2025-05-14'\n",
    "    AND topic_id = 238\n",
    "    AND NOT (\n",
    "        CONTAINS_SUBSTR(text, \"Estadio GNP\") \n",
    "        OR CONTAINS_SUBSTR(text, \"Auditorio GNP\") \n",
    "        OR CONTAINS_SUBSTR(text, \"el GNP\") \n",
    "        OR CONTAINS_SUBSTR(text, \"Foro GNP\")\n",
    "    )\n",
    "\"\"\"\n",
    "\n",
    "print(\"Query defined successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running query...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/google_cloud_proj/.venv/lib/python3.12/site-packages/google/cloud/bigquery/table.py:1957: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Query completed successfully\n",
      "✓ Retrieved 151 rows\n",
      "\n",
      "Columns: platform, creado, user_id, user, seguidores, text, likes, comentarios, compartidos, enganches, vistas\n"
     ]
    }
   ],
   "source": [
    "# Run query and get results as DataFrame\n",
    "print(\"Running query...\")\n",
    "try:\n",
    "    df = client.query(query).to_dataframe()\n",
    "    print(f\"✓ Query completed successfully\")\n",
    "    print(f\"✓ Retrieved {len(df):,} rows\")\n",
    "    print(f\"\\nColumns: {', '.join(df.columns)}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error running query: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preview Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 5 rows of data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>platform</th>\n",
       "      <th>creado</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user</th>\n",
       "      <th>seguidores</th>\n",
       "      <th>text</th>\n",
       "      <th>likes</th>\n",
       "      <th>comentarios</th>\n",
       "      <th>compartidos</th>\n",
       "      <th>enganches</th>\n",
       "      <th>vistas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Twitter</td>\n",
       "      <td>2025-05-13 17:12</td>\n",
       "      <td>1221543005485555712</td>\n",
       "      <td>annoying_girl99</td>\n",
       "      <td>141</td>\n",
       "      <td>@PulsoGNP @GNPSeguros Link de la preventa??? E...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Twitter</td>\n",
       "      <td>2025-05-12 23:09</td>\n",
       "      <td>882309131549511681</td>\n",
       "      <td>sarahiiifl</td>\n",
       "      <td>61</td>\n",
       "      <td>Bueno ya me rendí, véndame un boleto para Bad ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Facebook</td>\n",
       "      <td>2025-05-12 17:58</td>\n",
       "      <td>1747493702229048</td>\n",
       "      <td>Luli y Gabo</td>\n",
       "      <td>100298</td>\n",
       "      <td>¡Cuidado con asfixias o quemaduras! 🦖🚫🔥 La sup...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Twitter</td>\n",
       "      <td>2025-05-13 01:57</td>\n",
       "      <td>1821256511156580353</td>\n",
       "      <td>tiffpoilard</td>\n",
       "      <td>2</td>\n",
       "      <td>@wolfkeiira @Noyramo @youcantgetnohig El récor...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Twitter</td>\n",
       "      <td>2025-05-12 18:42</td>\n",
       "      <td>1657217841379041282</td>\n",
       "      <td>eusty92</td>\n",
       "      <td>5</td>\n",
       "      <td>@l_og2 ¿Sabes algo del Pulso GNP 2025?</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   platform            creado              user_id             user  \\\n",
       "0   Twitter  2025-05-13 17:12  1221543005485555712  annoying_girl99   \n",
       "1   Twitter  2025-05-12 23:09   882309131549511681       sarahiiifl   \n",
       "2  Facebook  2025-05-12 17:58     1747493702229048      Luli y Gabo   \n",
       "3   Twitter  2025-05-13 01:57  1821256511156580353      tiffpoilard   \n",
       "4   Twitter  2025-05-12 18:42  1657217841379041282          eusty92   \n",
       "\n",
       "  seguidores                                               text likes  \\\n",
       "0        141  @PulsoGNP @GNPSeguros Link de la preventa??? E...     0   \n",
       "1         61  Bueno ya me rendí, véndame un boleto para Bad ...     2   \n",
       "2     100298  ¡Cuidado con asfixias o quemaduras! 🦖🚫🔥 La sup...     7   \n",
       "3          2  @wolfkeiira @Noyramo @youcantgetnohig El récor...     1   \n",
       "4          5             @l_og2 ¿Sabes algo del Pulso GNP 2025?     0   \n",
       "\n",
       "  comentarios compartidos enganches vistas  \n",
       "0           0           0      None   None  \n",
       "1           0           0         2   None  \n",
       "2           0           0         7      0  \n",
       "3           1           0         2   None  \n",
       "4           0           0      None   None  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display first few rows\n",
    "print(\"\\nFirst 5 rows of data:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 151\n",
      "\n",
      "Platform distribution:\n",
      "platform\n",
      "Twitter     131\n",
      "Facebook     19\n",
      "YouTube       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Date range: 2025-05-12 00:02 to 2025-05-13 23:57\n"
     ]
    }
   ],
   "source": [
    "# Basic statistics\n",
    "print(f\"Total rows: {len(df):,}\")\n",
    "print(f\"\\nPlatform distribution:\")\n",
    "print(df['platform'].value_counts())\n",
    "print(f\"\\nDate range: {df['creado'].min()} to {df['creado'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Define aggregated query\naggregated_query = \"\"\"\nSELECT \n    DATE_TRUNC(created_at, DAY) AS fecha,\n    platform,\n    COUNT(DISTINCT activity_id) AS posts,\n    SUM(likes_reactions) as likes,\n    SUM(comments) AS comments,\n    SUM(shares_retweets) AS shares,\n    SUM(engagements) AS engagement,\n    SUM(views) AS views\nFROM `sinnia-gnp.social_dashboard_table.listening_table_prd`\nWHERE topic_id = 238 AND created_at >= '2025-01-01'\nGROUP BY 1,2\nORDER BY fecha\nLIMIT 1000\n\"\"\"\n\nprint(\"Aggregated query defined successfully\")"
  },
  {
   "cell_type": "code",
   "source": "# Run aggregated query and get results as DataFrame\nprint(\"Running aggregated query...\")\ntry:\n    agg_df = client.query(aggregated_query).to_dataframe()\n    print(f\"✓ Aggregated query completed successfully\")\n    print(f\"✓ Retrieved {len(agg_df):,} rows\")\n    print(f\"\\nColumns: {', '.join(agg_df.columns)}\")\n    \n    # Display first few rows\n    print(\"\\nFirst 5 rows of aggregated data:\")\n    print(agg_df.head())\n    \nexcept Exception as e:\n    print(f\"❌ Error running aggregated query: {e}\")",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Export aggregated data to CSV\nagg_filename = f'social_listening_aggregated_topic238_{timestamp}.csv'\nagg_filepath = os.path.join('data', agg_filename)\n\n# Export to CSV\nagg_df.to_csv(agg_filepath, index=False, encoding='utf-8')\nprint(f\"✓ Aggregated data exported to: {agg_filepath}\")\nprint(f\"✓ File size: {os.path.getsize(agg_filepath) / 1024:.2f} KB\")",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Export to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data directory if it doesn't exist\n",
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "# Generate filename with timestamp\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "filename = f'social_listening_topic238_{timestamp}.csv'\n",
    "filepath = os.path.join('data', filename)\n",
    "\n",
    "# Export to CSV\n",
    "df.to_csv(filepath, index=False, encoding='utf-8')\n",
    "print(f\"✓ Data exported to: {filepath}\")\n",
    "print(f\"✓ File size: {os.path.getsize(filepath) / 1024 / 1024:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Alternative: Direct Query to CSV (for large datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this method for very large datasets to avoid memory issues\n",
    "# Uncomment to use:\n",
    "\n",
    "# large_filename = f'social_listening_topic238_large_{timestamp}.csv'\n",
    "# large_filepath = os.path.join('data', large_filename)\n",
    "\n",
    "# # Export in chunks of 10,000 rows\n",
    "# query_to_csv(client, query, large_filepath, chunk_size=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The social listening data has been successfully exported. You can find your CSV file in the `data/` directory.\n",
    "\n",
    "### Next Steps:\n",
    "1. Check the exported CSV file in the `data/` folder\n",
    "2. Modify the date range in the query to export different time periods\n",
    "3. Adjust the topic_id to query different topics\n",
    "4. Add additional filters or columns as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}